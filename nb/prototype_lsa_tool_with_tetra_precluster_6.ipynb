{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano.tensor as tt\n",
    "import sys\n",
    "\n",
    "tt_simplex_normalize = lambda x: x / x.sum(1).reshape((x.shape[0], 1))\n",
    "tt_harmonic_mean = lambda x: 1 / tt.mean(1 / x)\n",
    "tt_generalized_mean = lambda x, r=1: tt.mean(x ** r) ** (1 / r)\n",
    "\n",
    "info = lambda s, *args: print(s % args, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_cvrg_path = 'data/sim/gut1_ecoli_conspecific.n4e6.z32.s00.a.backmap.cvrg.tsv'\n",
    "nlength_path = 'data/sim/gut1_ecoli_conspecific.n4e6.z32.s00.a.nlength.tsv'\n",
    "tax_cvrg_path = 'data/sim/gut1_ecoli_conspecific.n4e6.z32.s00.a.tax_counts.tsv'\n",
    "\n",
    "minlen = 200\n",
    "mintaxrabund = 0\n",
    "strain_reg_param1 = 1/3\n",
    "strain_reg_param2 = 10\n",
    "tax_fuzz_param = 1e-6\n",
    "seq_fuzz_param = 1e-6\n",
    "tax_uncertainty_param = 0.01\n",
    "\n",
    "info(\"Starting latent strain analysis.\")\n",
    "info(\"seq_cvrg_path: %s\", seq_cvrg_path)\n",
    "info(\"nlength_path: %s\", nlength_path)\n",
    "info(\"tax_cvrg_path: %s\", tax_cvrg_path)\n",
    "info(\"minlen: %f\", minlen)\n",
    "info(\"mintaxrabund: %f\", mintaxrabund)\n",
    "info(\"strain_reg_param1: %f\", strain_reg_param1)\n",
    "info(\"strain_reg_param2: %f\", strain_reg_param2)\n",
    "info(\"tax_fuzz_param: %f\", tax_fuzz_param)\n",
    "info(\"seq_fuzz_param: %f\", seq_fuzz_param)\n",
    "info(\"tax_uncertainty_param: %f\",tax_uncertainty_param)\n",
    "\n",
    "# Load data\n",
    "_seq_cvrg = pd.read_table(seq_cvrg_path,\n",
    "                      names=['sample_id', 'sequence_id', 'tally'],\n",
    "                      index_col=['sample_id', 'sequence_id'], squeeze=True\n",
    "                     ).unstack('sequence_id', fill_value=0)\n",
    "_seq_len = pd.read_table(nlength_path,\n",
    "                        names=['contig_id', 'nlength'], index_col=['contig_id'], squeeze=True)\n",
    "_tax_count = pd.read_table(tax_cvrg_path,\n",
    "                      names=['sample_id', 'taxon_id', 'tally'],\n",
    "                      index_col=['sample_id', 'taxon_id'], squeeze=True\n",
    "                     ).unstack('taxon_id', fill_value=0)\n",
    "\n",
    "# Align tables and drop low coverage dimensions.\n",
    "seq_cvrg = _seq_cvrg.reindex(columns=_seq_len[_seq_len > minlen].index).dropna(axis='columns')\n",
    "seq_len = _seq_len.loc[seq_cvrg.columns]\n",
    "tax_count = _tax_count.loc[seq_cvrg.index, _tax_count.divide(_tax_count.sum(1), axis=0).max() > mintaxrabund]\n",
    "# Scale to nucleotide counts\n",
    "seq_count = seq_cvrg.multiply(seq_len).round().astype(int)\n",
    "\n",
    "#\n",
    "# assert (seq_count.index == tax_count.index).all(), \"Sequence and taxon table indices must be aligned.\"\n",
    "# assert (seq_len.index == seq_count.columns).all(), \"Sequence and seq_len tables must be aligned.\"\n",
    "\n",
    "n_samples, g_seqs = seq_count.shape\n",
    "t_taxa = tax_count.shape[1]\n",
    "s_strains = int(np.ceil(1.5 * t_taxa))\n",
    "u_tax_counts = tax_count.sum(1).round().astype(int)\n",
    "v_seq_counts = seq_count.sum(1).round().astype(int)\n",
    "\n",
    "info(\"n_samples: %d\", n_samples)\n",
    "info(\"g_seqs: %d\", g_seqs)\n",
    "info(\"t_taxa: %d\", t_taxa)\n",
    "info(\"s_strains: %d\", s_strains)\n",
    "info(\"mean u_tax_counts: %f\", u_tax_counts.mean())\n",
    "info(\"mean v_seq_counts: %f\", v_seq_counts.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_path = 'data/sim/gut1_ecoli_conspecific.n4e6.z32.s00.a.k4.tsv'\n",
    "_seq_kmer = (pd.read_table(kmer_path, names=['contig_id', 'kmer', 'tally'],\n",
    "                      index_col=['contig_id', 'kmer'],\n",
    "                      squeeze=True)\n",
    "               .unstack(fill_value=0))\n",
    "seq_kmer = _seq_kmer.reindex(seq_len.index)\n",
    "\n",
    "seq_kmer = seq_kmer + 1\n",
    "seq_kmer = seq_kmer.divide(seq_kmer.sum(1), axis=0)\n",
    "seq_kmer = np.log(seq_kmer).apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.90\n",
    "\n",
    "pca = PCA().fit(seq_kmer)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "ncomps = (np.cumsum(pca.explained_variance_ratio_) < thresh).sum() + 1\n",
    "plt.axhline(thresh)\n",
    "plt.axvline(ncomps)\n",
    "\n",
    "kmer_coords = pca.transform(seq_kmer)[:,:ncomps]\n",
    "plt.figure()\n",
    "plt.scatter(kmer_coords[:,0], kmer_coords[:,1], s=0.5)\n",
    "\n",
    "kmer_coords = pd.DataFrame(kmer_coords, index=seq_kmer.index, columns=[f'PC{i}' for i in range(ncomps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_coords = np.log((seq_cvrg + (100 / seq_len)).T).apply(lambda x: (x - x.mean()) / x.std())\n",
    "plt.scatter(cvrg_coords['gut1_ecoli_conspecific.n4e6.s0000'], cvrg_coords['gut1_ecoli_conspecific.n4e6.s0001'], s=0.1)\n",
    "#plt.xlim(-10, 200)\n",
    "#plt.ylim(-10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_coords = cvrg_coords.join(kmer_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=s_strains*10, verbose=2, n_init=1).fit(raw_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_clust = pd.Series(km.predict(raw_coords), index=seq_len.index)\n",
    "#plt.scatter(viz_coords[:,0], viz_coords[:,1], s=0.5, c=seq_clust, cmap=mpl.cm.gist_rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for ax, (i, j) in zip(axs.flatten(), [(1, 2), (3, 4), (5, 6), (7, 8)]):\n",
    "    ax.scatter(raw_coords[f'gut1_ecoli_conspecific.n4e6.s000{i}'],\n",
    "               raw_coords[f'gut1_ecoli_conspecific.n4e6.s000{j}'],\n",
    "               s=0.1, c=seq_clust, cmap=mpl.cm.gist_rainbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_count = seq_count.groupby(seq_clust, axis=1).sum()\n",
    "clust_len = seq_len.groupby(seq_clust).sum()\n",
    "\n",
    "clust_cvrg = clust_count.divide(clust_len)\n",
    "#plt.imshow(clust_cvrg, aspect='auto')\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_len.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clust_len.sort_values().values)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, g_clusts = clust_count.shape\n",
    "t_taxa = tax_count.shape[1]\n",
    "s_strains = int(np.ceil(1.5 * t_taxa))\n",
    "u_tax_counts = tax_count.sum(1).round().astype(int)\n",
    "v_clust_counts = clust_count.sum(1).round().astype(int)\n",
    "\n",
    "info(\"n_samples: %d\", n_samples)\n",
    "info(\"g_clusts: %d\", g_clusts)\n",
    "info(\"t_taxa: %d\", t_taxa)\n",
    "info(\"s_strains: %d\", s_strains)\n",
    "info(\"mean u_tax_counts: %f\", u_tax_counts.mean())\n",
    "info(\"mean v_clust_counts: %f\", v_clust_counts.mean())\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Latent strain abundances\n",
    "    pi = pm.Dirichlet('pi', a=np.ones(s_strains), shape=(n_samples, s_strains))\n",
    "    pi_reg = pm.Potential('pi_reg', -strain_reg_param2 * tt_generalized_mean(pi, strain_reg_param1))\n",
    "\n",
    "\n",
    "    # Strains to taxa\n",
    "    theta = pm.Dirichlet('theta',\n",
    "                        a=np.ones(t_taxa) * tax_uncertainty_param / t_taxa,\n",
    "                        shape=(s_strains, t_taxa))\n",
    "    expect_tax_frac_unnorm = pi.dot(theta) + tax_fuzz_param\n",
    "    obs_tax = pm.Multinomial('obs_tax',\n",
    "                            n=u_tax_counts,\n",
    "                            p=expect_tax_frac_unnorm,\n",
    "                            shape=(n_samples, t_taxa),\n",
    "                            observed=tax_count.values)\n",
    "\n",
    "    # Strains to clusts\n",
    "    # phi = pm.Exponential('phi', lam=1, shape=(s_strains, g_clusts))  # Too much mass at intermediate values\n",
    "    phi = pm.Weibull('phi', alpha=0.1, beta=0.1, shape=(s_strains, g_clusts))\n",
    "    expect_clust_frac_unnorm = pi.dot(phi) * clust_len + seq_fuzz_param\n",
    "\n",
    "\n",
    "    obs_clust = pm.Multinomial('obs_clust',\n",
    "                            n=v_clust_counts,\n",
    "                            p=expect_clust_frac_unnorm,\n",
    "                            shape=(n_samples, g_clusts),\n",
    "                            observed=clust_count.values)\n",
    "\n",
    "    # Save intermediate values:\n",
    "    pm.Deterministic('expect_tax_frac', tt_simplex_normalize(expect_tax_frac_unnorm))\n",
    "    pm.Deterministic('expect_clust_frac', tt_simplex_normalize(expect_clust_frac_unnorm))\n",
    "\n",
    "\n",
    "advi = pm.fit(int(1.5e5), model=model)\n",
    "info(\"Finished fitting model with ADVI.\")\n",
    "advi_mean = advi.bij.rmap(advi.mean.eval())\n",
    "\n",
    "strain_names = [f's{i:03}' for i in range(s_strains)]\n",
    "\n",
    "theta_est = model.theta.eval({model.theta_stickbreaking__: advi_mean['theta_stickbreaking__']})\n",
    "phi_est = model.phi.eval({model.phi_log__: advi_mean['phi_log__']})\n",
    "pi_est = model.pi.eval({model.pi_stickbreaking__: advi_mean['pi_stickbreaking__']})\n",
    "\n",
    "info(\"DONE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(advi.hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_theta_est = theta_est\n",
    "_phi_est = phi_est\n",
    "_pi_est = pi_est\n",
    "\n",
    "theta_est = pd.DataFrame(_theta_est, index=strain_names, columns=tax_count.columns)\n",
    "phi_est = pd.DataFrame(_phi_est, columns=clust_count.columns, index=strain_names)\n",
    "pi_est = pd.DataFrame(_pi_est, columns=strain_names, index=clust_count.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save results\n",
    "theta_est.to_csv('lsa_theta_est.tsv', sep='\\t')\n",
    "phi_est.to_csv('lsa_phi_est.tsv', sep='\\t')\n",
    "pi_est.to_csv('lsa_pi_est.tsv', sep='\\t')\n",
    "seq_clust.to_frame().rename(columns={0: 'clust'}).to_csv('lsa_seq_clust.tsv', sep='\\t')\n",
    "\n",
    "## Load results\n",
    "#theta_est = pd.read_table('lsa_theta_est.tsv')\n",
    "#phi_est = pd.read_table('lsa_phi_est.tsv')\n",
    "#pi_est = pd.read_table('lsa_pi_est.tsv')\n",
    "#seq_clust = pd.read_table('lsa_seq_clust.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(pi_est.mean(0), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much sequence per taxonomic category was contributed by each strain?\n",
    "# Given a single taxon, scale the gene content of each strain by how likely it is\n",
    "# to be in that taxon, and then scale it by how common the taxon is.\n",
    "\n",
    "strain_size = (phi_est * clust_len.values).sum(1)\n",
    "\n",
    "per_tax_contrib = np.empty_like(theta_est)\n",
    "for i, t in enumerate(tax_count.columns):\n",
    "    per_tax_contrib[:,i] = (pi_est * theta_est.values[:,i] * strain_size).mean(0)\n",
    "\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.imshow(per_tax_contrib.T, aspect='auto')\n",
    "plt.yticks(ticks=range(tax_count.shape[1]), labels=tax_count.columns)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(phi_est.loc[:,(clust_len > 5000)], metric='cosine', standard_scale=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(theta_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(theta_est, columns=tax_count.columns)\n",
    "d['Escherichia_coli_58110'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = pd.DataFrame(phi_est, columns=clust_len.index).T.join(clust_len)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "for strain in ['s118', 's064', 's073']:\n",
    "    cumlen = d0.sort_values(strain, ascending=False).nlength.cumsum()\n",
    "    d1 = d0[[strain]].copy()\n",
    "    d1['cumlen'] = cumlen\n",
    "    d1 = d1.sort_values('cumlen', ascending=False)\n",
    "    ax.plot(strain, 'cumlen', data=d1, label=strain)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlim(1, 200)\n",
    "ax.set_ylim(1, 1e7)\n",
    "ax.legend()\n",
    "#for x in [0.2, 0.5, 1]:\n",
    "#    ax.axvline(x=x, color='k', lw=0.5, linestyle='--')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = d0[['s146']].join(clust_len).sort_values('s146', ascending=False)\n",
    "d['cumlen'] = np.cumsum(d.nlength)\n",
    "d.head(100).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_phi_est = seq_clust.apply(lambda x: phi_est[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(seq_phi_est).round(1).to_csv('test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.array([0, 2, 5, 10])\n",
    "seq_phi_est.apply(lambda x: np.digitize(x, bins)).to_csv('test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(seq_phi_est).loc['k101_5668'].sort_values().values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}