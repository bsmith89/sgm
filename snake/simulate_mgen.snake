import pandas as pd
from lib.snake import alias_recipe, alias_fmt, curl_recipe, curl_unzip_recipe

wildcard_constraints:
    genome_id='[^.]*',
    sample_id='[^.]*',
    nreads='[0-9.]+[kKmMgG]',
    seed='[0-9]{1,4}'

_genome = pd.read_table(config['_genome'], index_col='genome_id')
config['ftp_stem'] = _genome.ftp_stem.to_dict()

_community = pd.read_table('meta/sim/community.tsv')
config['community'] = {}
for community_id, d in _community.groupby('community_id'):
    config['community'][community_id] = d.genome_id.tolist()

rule download_refseq_genome:
    output: 'raw/genome/{genome}.fn'
    params:
        url=lambda w: config['ftp_stem'][w.genome] + '_genomic.fna.gz'
    resources:
        net_requests_per_second=1
    shell:
        '''
        sleep 1
        echo "Downloading {wildcards.genome} from {params.url}"
        curl {params.url} | zcat > {output}
        grep --quiet '^>' {output} || (echo "No FASTA records found in {output}" && false)
        '''

rule link_reference_genome:
    output: 'ref/genome/{genome}.fn'
    input: 'raw/genome/{genome}.fn'
    shell: alias_recipe

rule simulate_community_mgen:
    output:
        r1='data/sim/{community}.s{seed}.n{nreads}.m.r1.fq',
        r2='data/sim/{community}.s{seed}.n{nreads}.m.r2.fq',
        abund='data/sim/{community}.s{seed}.n{nreads}.abund.tsv'
    input:
        script='scripts/simulate_community_mgen.py',
        replicon='data/replicon.tsv',
        community='meta/sim/community.tsv',
        genomes=lambda w: expand('ref/genome/{genome}.fn', genome=config['community'][w.community])
    wildcard_constraints:
        nreads='[0-9]*'
    params:
        genomes_dir='ref/genome/'
    shell:
        '''
        {input.script} {input.community} {wildcards.community} {input.replicon} \
                {params.genomes_dir} {wildcards.nreads} {wildcards.seed} \
                {output.abund} {output.r1} {output.r2}
        '''


rule combine_with_background1_mgen_reads:
    output:
        r1='data/sim/{community}.wgut1.s{seed}.n{nreads}-{mreads}.m.r1.fq.gz',
        r2='data/sim/{community}.wgut1.s{seed}.n{nreads}-{mreads}.m.r2.fq.gz'
    input:
        r1_back='data/sim/background_gut_1.s{seed}.n{mreads}.m.r1.fq',
        r2_back='data/sim/background_gut_1.s{seed}.n{mreads}.m.r2.fq',
        r1_std='data/sim/{community}.s{seed}.n{nreads}.m.r1.fq',
        r2_std='data/sim/{community}.s{seed}.n{nreads}.m.r2.fq'
    wildcard_constraints:
        nreads='[0-9]*',
        mreads='[0-9]*'
    threads: 2
    shell:
        '''
            cat {input.r1_back} {input.r1_std} | gzip -c > {output.r1} & pid1=$!
            cat {input.r2_back} {input.r2_std} | gzip -c > {output.r2} & pid2=$!
            for pid in $pid1 $pid2
            do
                wait $pid || [ "$?" -eq 127 ]
            done

        '''

# TODO: Make simulated communities by combining a certain number of reads from other organisms
# TODO: rule combine_reads_into_mgen:
            # .m. infix for shotgun "metagenome" reads (one or more genomes)
#           output:
#               r1='data/sim/{sample_id}.m.s{seed}.n{nreads}.r1.fq.gz
#               r2='data/sim/{sample_id}.m.s{seed}.n{nreads}.r2.fq.gz


rule quality_trim_reads:
    output:
        r1='data/sim/{stem}.qtrim.r1.fq.gz',
        r2='data/sim/{stem}.qtrim.r2.fq.gz',
        r3='data/sim/{stem}.qtrim.r3.fq.gz'
    input:
        r1='data/sim/{stem}.r1.fq.gz',
        r2='data/sim/{stem}.r2.fq.gz'
    params:
        qual_type='sanger',
        qual_thresh=20
    shell:
        '''
        sickle pe -t {params.qual_type} -q {params.qual_thresh} --gzip-output \
            --pe-file1 {input.r1} --pe-file2 {input.r2} \
            --output-pe1 {output.r1} --output-pe2 {output.r2} \
            --output-single {output.r3}
        '''

rule assemble_mgen:
    output:
        fasta='data/sim/{stem}.asmbl.fn',
        fastg='data/sim/{stem}.asmbl.fg'
    input:
        r1='data/sim/{stem}.qtrim.r1.fq.gz',
        r2='data/sim/{stem}.qtrim.r2.fq.gz'
    params:
        kmin=21,
        kmax=101,
        kstep=20,
        outdir=lambda w: f'data/sim/{stem}.asmbl.d'
    threads: MAX_THREADS
    log: 'log/{stem}.asmbl.log'
    shell:
        '''
        tmpdir=$(mktemp -du)
        echo "Running MEGAHIT with outdir $tmpdir"
        megahit \
            -1 {input.r1} \
            -2 {input.r2} \
            --k-min {params.kmin} --k-max {params.kmax} --k-step {params.kstep} \
            --out-dir $tmpdir \
            --num-cpu-threads {threads} \
            --verbose \
            | tee 2>&1 > {log}
        cp $tmpdir/final.contigs.fa {output.fasta}
        megahit_toolkit contig2fastg {params.kmax} $tmpdir/intermediate_contigs/k{params.kmax}.contigs.fa > {output.fastg}
        '''

rule quality_asses_assembly_with_mg1655:
    output: directory('data/sim/{stem}.asmbl.quast.d')
    input:
        contigs='data/sim/{stem}.asmbl.fn',
        genome=lambda w: [f'ref/genome/{accession}.fn'
                           for accession
                           in config['sim_sample']['ecoli_k12_mg1655']]
    threads: 4
    shell:
        '''
        metaquast.py --threads {threads} -r {input.genome} --output-dir {output} {input.contigs}
        '''
