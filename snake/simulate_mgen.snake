import pandas as pd
from lib.snake import alias_recipe, alias_fmt, curl_recipe, curl_unzip_recipe

wildcard_constraints:
    genome_id='[^.]*',
    sample_id='[^.]*',
    nreads='[0-9.]+[kKmMgG]',
    seed='[0-9]{1,4}'

_genome = pd.read_table(config['_genome'], index_col='genome_id')
config['genome_to_refseq_url_stem'] = _genome.refseq_ftp_url_stem.to_dict()

rule download_refseq_genome:
    output: 'raw/genome/{genome}.fn'
    params:
        url=lambda w: config['genome_to_refseq_url_stem'][w.genome] + '_genomic.fna.gz'
    shell:
        '''
        echo "Downloading {wildcards.genome} from {params.url}"
        curl {params.url} | zcat > {output}
        grep --quiet '^>' {output} || (echo "No FASTA records found in {output}" && false)
        '''

rule link_reference_genome:
    output: 'ref/genome/{genome}.fn'
    input: 'raw/genome/{genome}.fn'
    shell: alias_recipe

rule simulate_genome_reads:
    # .s. infix for "shotgun" reads (single genome)
    output:
        r1='data/sim/{genome_id}.s.s{seed}.n{nreads}.r1.fq.gz',
        r2='data/sim/{genome_id}.s.s{seed}.n{nreads}.r2.fq.gz'
    input:
        genome='ref/genome/{genome_id}.fn'
    threads: 6
    shell:
        '''
        tmpdir=$(mktemp -d)
        echo "Writing simulation results for sample {wildcards.genome_id} to $tmpdir"
        iss generate --genome {input.genome} --model HiSeq -n {wildcards.nreads} --seed {wildcards.seed} --cpus {threads} --output $tmpdir/
        gzip -c $tmpdir/_R1.fastq > {output.r1} & pid1=$!
        gzip -c $tmpdir/_R2.fastq > {output.r2} & pid2=$!
        for pid in $pid1 $pid2
        do
            wait $pid || [ "$?" -eq 127 ]
        done
        '''

# TODO: Make simulated communities by combining a certain number of reads from other organisms
# TODO: rule combine_reads_into_mgen:
            # .m. infix for shotgun "metagenome" reads (one or more genomes)
#           output:
#               r1='data/sim/{sample_id}.m.s{seed}.n{nreads}.r1.fq.gz
#               r2='data/sim/{sample_id}.m.s{seed}.n{nreads}.r2.fq.gz


rule quality_trim_reads:
    output:
        r1='data/sim/{stem}.qtrim.r1.fq.gz',
        r2='data/sim/{stem}.qtrim.r2.fq.gz',
        r3='data/sim/{stem}.qtrim.r3.fq.gz'
    input:
        r1='data/sim/{stem}.r1.fq.gz',
        r2='data/sim/{stem}.r2.fq.gz'
    params:
        qual_type='sanger',
        qual_thresh=20
    shell:
        '''
        sickle pe -t {params.qual_type} -q {params.qual_thresh} --gzip-output \
            --pe-file1 {input.r1} --pe-file2 {input.r2} \
            --output-pe1 {output.r1} --output-pe2 {output.r2} \
            --output-single {output.r3}
        '''

rule assemble_mgen:
    output:
        fasta='data/sim/{stem}.asmbl.fn',
        fastg='data/sim/{stem}.asmbl.fg'
    input:
        r1='data/sim/{stem}.qtrim.r1.fq.gz',
        r2='data/sim/{stem}.qtrim.r2.fq.gz'
    params:
        kmin=21,
        kmax=101,
        kstep=20,
        outdir=lambda w: f'data/sim/{stem}.asmbl.d'
    threads: MAX_THREADS
    log: 'log/{stem}.asmbl.log'
    shell:
        '''
        tmpdir=$(mktemp -du)
        echo "Running MEGAHIT with outdir $tmpdir"
        megahit \
            -1 {input.r1} \
            -2 {input.r2} \
            --k-min {params.kmin} --k-max {params.kmax} --k-step {params.kstep} \
            --out-dir $tmpdir \
            --num-cpu-threads {threads} \
            --verbose \
            | tee 2>&1 > {log}
        cp $tmpdir/final.contigs.fa {output.fasta}
        megahit_toolkit contig2fastg {params.kmax} $tmpdir/intermediate_contigs/k{params.kmax}.contigs.fa > {output.fastg}
        '''

rule quality_asses_assembly_with_mg1655:
    output: directory('data/sim/{stem}.asmbl.quast.d')
    input:
        contigs='data/sim/{stem}.asmbl.fn',
        genome=lambda w: [f'ref/genome/{accession}.fn'
                           for accession
                           in config['sim_sample']['ecoli_k12_mg1655']]
    threads: 4
    shell:
        '''
        metaquast.py --threads {threads} -r {input.genome} --output-dir {output} {input.contigs}
        '''
