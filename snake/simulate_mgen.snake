import pandas as pd
from lib.snake import alias_recipe, alias_fmt, curl_recipe, curl_unzip_recipe
import glob
import os.path

wildcard_constraints:
    genome_id='[^.]*',
    sample_id='[^.]*',
    nreads='[0-9e]*',
    seed='[0-9]{1,4}'

_genome = pd.read_table(config['_genome'], index_col='genome_id')
config['ftp_stem'] = _genome.ftp_stem.to_dict()


config['community'] = {}
_community_dir = config['_community_dir']
for path in glob.glob(os.path.join(_community_dir, '*.tsv')):
    basename = os.path.basename(path)[:-4]
    _community = pd.read_table(path)
    config['community'][basename] = _community.genome_id.tolist()

rule download_ncbi_taxdump:
    output: 'raw/ref/new_taxdump.tar.gz'
    params:
        url='https://ftp.ncbi.nlm.nih.gov/pub/taxonomy/new_taxdump/new_taxdump.zip'
    shell: curl_recipe

rule unpack_ncbi_taxonomy:
    output: 'ref/ncbi_taxonomy.tsv'
    input: 'raw/ref/new_taxdump.tar.gz'
    shell:
        r'''
        tmpdir=$(mktemp -d)
        echo $tmpdir
        tar -C $tmpdir -xzvf {input}
        cat $tmpdir/rankedlineage.dmp | sed 's:\t|\t\?:\t:g' | awk -v FS='\t' -v OFS='\t' '{{print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10}}' > {output}
        '''

rule download_refseq_genome:
    output: 'raw/genome/{genome}.fn'
    params:
        url=lambda w: config['ftp_stem'][w.genome] + '_genomic.fna.gz'
    resources:
        net_requests_per_second=1
    shell:
        '''
        sleep 1
        echo "Downloading {wildcards.genome} from {params.url}"
        curl {params.url} | zcat > {output}
        grep --quiet '^>' {output} || (echo "No FASTA records found in {output}" && false)
        '''

rule link_reference_genome:
    output: 'ref/genome/{genome}.fn'
    input: 'raw/genome/{genome}.fn'
    shell: alias_recipe

rule simulate_community_mgen:
    output:
        r1='data/sim/{community}.n{nreads}.s{seed}.m.r1.fq.gz',
        r2='data/sim/{community}.n{nreads}.s{seed}.m.r2.fq.gz',
        abund='data/sim/{community}.n{nreads}.s{seed}.m.abund.tsv'
    input:
        script='scripts/simulate_community_mgen.py',
        replicon='data/replicon.tsv',
        community='meta/sim/community/{community}.tsv',
        genomes=lambda w: expand('ref/genome/{genome}.fn', genome=config['community'][w.community])
    params:
        genomes_dir='ref/genome/'
    shell:
        '''
        pipe_r1=$(mktemp -u) && mkfifo $pipe_r1
        pipe_r2=$(mktemp -u) && mkfifo $pipe_r2
        gzip -c < $pipe_r1 > {output.r1} & pid1=$!
        gzip -c < $pipe_r2 > {output.r2} & pid2=$!
        {input.script} {input.community} {wildcards.community} {input.replicon} \
                {params.genomes_dir} {wildcards.nreads} {wildcards.seed} \
                {output.abund} $pipe_r1 $pipe_r2
        for pid in $pid1 $pid2
        do
            wait $pid || [ "$?" -eq 127 ]
        done
        '''

rule quality_trim_reads:
    output:
        r1='data/sim/{stem}.qtrim.r1.fq.gz',
        r2='data/sim/{stem}.qtrim.r2.fq.gz',
        r3='data/sim/{stem}.qtrim.r3.fq.gz'
    input:
        r1='data/sim/{stem}.r1.fq.gz',
        r2='data/sim/{stem}.r2.fq.gz'
    params:
        qual_type='sanger',
        qual_thresh=20
    shell:
        '''
        sickle pe -t {params.qual_type} -q {params.qual_thresh} --gzip-output \
            --pe-file1 {input.r1} --pe-file2 {input.r2} \
            --output-pe1 {output.r1} --output-pe2 {output.r2} \
            --output-single {output.r3}
        '''

# {seed} here is not the simulated mgen seed, but the seed for the simulated SET of reads.
rule assemble_mgen_samples:
    output:
        fasta='data/sim/{community}.n{nreads}.z{nsamples}.s{seed}.a.fn',
        fastg='data/sim/{community}.n{nreads}.z{nsamples}.s{seed}.a.fg',
        abund='data/sim/{community}.n{nreads}.z{nsamples}.s{seed}.a.abund.tsv'
    input:
        r1=lambda w: [f'data/sim/{{community}}.n{{nreads}}.s{seed:04}.m.qtrim.r1.fq.gz'
                      for seed
                      in range(int(w.nsamples) * int(w.seed),
                               int(w.nsamples) * (int(w.seed) + 1)
                              )],
        r2=lambda w: [f'data/sim/{{community}}.n{{nreads}}.s{seed:04}.m.qtrim.r2.fq.gz'
                      for seed
                      in range(int(w.nsamples) * int(w.seed),
                               int(w.nsamples) * (int(w.seed) + 1)
                              )],
        abund=lambda w: [f'data/sim/{{community}}.n{{nreads}}.s{seed:04}.m.abund.tsv'
                         for seed
                         in range(int(w.nsamples) * int(w.seed),
                                 int(w.nsamples) * (int(w.seed) + 1)
                                 )]
    params:
        r1_list=lambda w, input: ','.join(input.r1),
        r2_list=lambda w, input: ','.join(input.r2),
        k_list='21,41,61,81,101',
        k_max=101,
        outdir='data/sim/{community}.n{nreads}.z{nsamples}.s{seed}.a.d'
    threads: 8
    log: 'log/{community}.n{nreads}.z{nsamples}.s{seed}.a.log'
    shell:
        '''
        for file in {input.abund}
        do
            awk -v OFS='\t' -v sample_id=$(basename --suffix .m.abund.tsv $file) '{{print sample_id,$1,$2}}' $file
        done > {output.abund}
        tmpdir=$(mktemp -du)
        echo "Running MEGAHIT with outdir $tmpdir"
        megahit \
            -1 {params.r1_list} \
            -2 {params.r2_list} \
            --k-list {params.k_list} \
            --out-dir $tmpdir \
            --num-cpu-threads {threads} \
            --verbose \
            2>&1 | tee > {log}
        cp $tmpdir/final.contigs.fa {output.fasta}
        megahit_toolkit contig2fastg {params.k_max} $tmpdir/intermediate_contigs/k{params.k_max}.contigs.fa > {output.fastg}
        '''

rule quality_asses_assembly:
    output:
        fasta=directory('data/sim/{community}.n{nreads}.z{nsamples}.s{seed}.a.quast.d')
    input:
        contigs='data/sim/{community}.n{nreads}.z{nsamples}.s{seed}.a.fn',
        genomes=lambda w: expand('ref/genome/{genome}.fn', genome=config['community'][w.community])
    params:
        genomes_list=lambda w, input: ','.join(input.genomes)
    threads: 8
    shell:
        '''
        tmpdir=$(mktemp -d)
        echo "Building {output} at $tmpdir ."
        metaquast.py --threads {threads} -r {params.genomes_list} --output-dir $tmpdir {input.contigs}
        mv $tmpdir {output}
        '''
